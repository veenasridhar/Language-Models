A simple character level language model using transformer architecture from the paper "Attention is all you need" to understand the basics of a transformer architecture and a large langugae model.
The model is given a 1115394 length of shakespearean text and it generated shakespearean like text


Ref:https://github.com/karpathy/ng-video-lecture
